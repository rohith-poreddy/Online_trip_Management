<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Securing malloc in glibc: Why malloc hooks had to go</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gLP8-dV0DFI/securing-malloc-glibc-why-malloc-hooks-had-go" /><author><name>Siddhesh Poyarekar</name></author><id>0accb512-3e3e-4517-8638-6fdf07c07f2d</id><updated>2021-08-25T07:00:00Z</updated><published>2021-08-25T07:00:00Z</published><summary type="html">&lt;p&gt;Memory access is one of the most basic operations in computer programs. It is also an unending source of program errors in C programs, because memory safety was never really a programming language goal in C. Memory-related issues also comprise a significant part of the &lt;a href="https://cwe.mitre.org/top25/archive/2021/2021_cwe_top25.html"&gt;top 25 security weaknesses&lt;/a&gt; that result in program vulnerabilities.&lt;/p&gt; &lt;p&gt;Memory access also plays an important role in performance, which makes memory management a prime target for performance tuning. It is natural, then, that dynamic memory management in the C runtime should have capabilities that allow fine-grained tracking and customizable actions on allocation events. These features allow users to diagnose memory issues in their programs and if necessary, override the C runtime allocator with their own to improve performance or memory utilization.&lt;/p&gt; &lt;p&gt;This article describes the clash between the quest for flexibility and introspection, on the one hand, and performance and security protections on the other. You'll learn why this clash ultimately led to a major change in how memory allocation (&lt;code&gt;malloc&lt;/code&gt;) is implemented in the &lt;a href="http://www.gnu.org/software/libc/libc.html"&gt;GNU C Library&lt;/a&gt;, or glibc. We'll also discuss how to adapt applications that depended on the old way of doing things, as well as the implications for future versions of Fedora and &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL).&lt;/p&gt; &lt;h2&gt;Debugging malloc in glibc&lt;/h2&gt; &lt;p&gt;Until recently, the GNU C Library, which is the core runtime library for RHEL, provided diagnostic functionality in the form of function pointers that users could overwrite to implement their own allocation functions. These function pointers were collectively called &lt;em&gt;malloc hooks&lt;/em&gt;. If a hook was set to a function address, glibc allocator functions would call the function instead of the internal implementations, allowing programmers to perform arbitrary actions. A programmer could even run a custom function and then, if necessary, call the glibc memory allocator function again (by momentarily setting the hook to &lt;code&gt;NULL&lt;/code&gt;) to get the actual block of memory.&lt;/p&gt; &lt;p&gt;All of the malloc debugging features in glibc (i.e., &lt;code&gt;mtrace&lt;/code&gt;, &lt;code&gt;mcheck&lt;/code&gt;, and the &lt;code&gt;MALLOC_CHECK_&lt;/code&gt; environment variable) were implemented using these hooks. These debugging features, and the hooks in general, were very useful because they provided checking on a more lightweight basis than the memory checking done by full-fledged memory debugging programs such as &lt;a href="https://developers.redhat.com/blog/2021/04/23/valgrind-memcheck-different-ways-to-lose-your-memory"&gt;Valgrind&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/2021/05/05/memory-error-checking-in-c-and-c-comparing-sanitizers-and-valgrind"&gt;sanitizers&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Malloc hooks in multi-threaded applications&lt;/h2&gt; &lt;p&gt;As applications became increasingly multi-threaded, it was discovered that manipulating malloc hooks in such environments was fraught with risks. All of the debugging features in glibc malloc except &lt;code&gt;MALLOC_CHECK_&lt;/code&gt; were, and continue to be, unsafe in multi-threaded environments. Malloc hooks, the basis of the debugging features, were not the only way to override malloc, either; glibc always supported the &lt;a href="https://www.gnu.org/software/libc/manual/html_node/Replacing-malloc.html#Replacing-malloc"&gt;interposition of malloc functions&lt;/a&gt; by preloading a shared library with those functions. Glibc itself always calls malloc functions through its procedure linkage table (PLT) so that it can invoke the interposed functions.&lt;/p&gt; &lt;p&gt;To make things worse, much of the debugging infrastructure was tightly integrated into system allocator functionality. This made the task of enhancing the allocator unnecessarily complex. Furthermore, there was always the possibility of corner cases inducing unexpected behavior. Finally, implementing debugging features in the system allocator created a minor but unnecessary performance overhead.&lt;/p&gt; &lt;p&gt;The key misfeature of the debugging hooks, though, was their presence as unprotected function pointers that were guaranteed to be executed at specific events. This made the hooks an &lt;a href="https://gist.github.com/romanking98/9aab2804832c0fb46615f025e8ffb0bc"&gt;easy exploit primitive&lt;/a&gt; in practically every program that ran on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; distributions. A trivial search for &lt;a href="https://duckduckgo.com/?q=__malloc_hook+%22house+of%22"&gt;__malloc_hook "house of"&lt;/a&gt; turns up a long list of exploit methods that use the hooks as either an intermediate step or the final goal for the exploit.&lt;/p&gt; &lt;p&gt;Malloc hooks had to go.&lt;/p&gt; &lt;h2&gt;Excising malloc hooks from the main library&lt;/h2&gt; &lt;p&gt;The last of the malloc hook variables were deprecated in glibc 2.32 and new applications were encouraged to use malloc interposition instead. The effect of deprecation was mild: Newer applications just got a warning during the build. In the interest of maintaining backward compatibility, the memory allocator continued to look for hooks and, if available, execute them. In glibc version 2.34 (August 2021), we finally bit the bullet and took support for malloc hooks out of the mainstream library.&lt;/p&gt; &lt;p&gt;The upstream glibc community agreed that malloc debugging features have no place in production. So we moved all debugging features into a separate library named &lt;code&gt;libc_malloc_debug.so.0&lt;/code&gt; that overrides system malloc behavior to enable debugging. Most importantly, we either moved unprotected hook function pointers into &lt;code&gt;libc_malloc_debug.so.0&lt;/code&gt; or removed them completely. Doing this eliminated a key exploit primitive from the library.&lt;/p&gt; &lt;h2&gt;Debugging and hardening in a post-hook world&lt;/h2&gt; &lt;p&gt;The new glibc without the problematic hooks will be available in future versions of Fedora and RHEL. With this glibc, malloc debugging features such as &lt;code&gt;MALLOC_CHECK_&lt;/code&gt;, &lt;code&gt;mtrace()&lt;/code&gt;, and &lt;code&gt;mcheck()&lt;/code&gt; will no longer work by default. Users will need to preload &lt;code&gt;libc_malloc_debug.so.0&lt;/code&gt; to enable these debugging features. Additionally, the &lt;code&gt;__after_morecore_hook&lt;/code&gt;, &lt;code&gt;__default_morecore_hook&lt;/code&gt;, and &lt;code&gt;__morecore&lt;/code&gt; function pointers are no longer read, and the system malloc uses the &lt;code&gt;brk()&lt;/code&gt; and &lt;code&gt;mmap()&lt;/code&gt; system calls to request memory from the kernel.&lt;/p&gt; &lt;p&gt;System administrators may also remove the library from the system and effectively disable malloc debugging and malloc hooks. This is useful hardening for production systems that have strong controls on what files are available on the system.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Separating malloc debugging from the main library is a significant security hardening improvement in glibc. It eliminates an exploit primitive from Linux distributions and adds an opportunity for hardening in both RHEL and Fedora. Simplifying system allocator code also sets the stage for improvements to malloc that may result in better security and performance. Watch out for more interesting changes to the malloc subsystem in future releases of glibc.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/08/25/securing-malloc-glibc-why-malloc-hooks-had-go" title="Securing malloc in glibc: Why malloc hooks had to go"&gt;Securing malloc in glibc: Why malloc hooks had to go&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gLP8-dV0DFI" height="1" width="1" alt=""/&gt;</summary><dc:creator>Siddhesh Poyarekar</dc:creator><dc:date>2021-08-25T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/08/25/securing-malloc-glibc-why-malloc-hooks-had-go</feedburner:origLink></entry><entry><title type="html">RESTEasy Reactive - To block or not to block</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/nCCiwUoAHPg/" /><author><name>Clement Escoffier</name></author><id>https://quarkus.io/blog/resteasy-reactive-smart-dispatch/</id><updated>2021-08-25T00:00:00Z</updated><content type="html">In January 2021, the Quarkus team announced RESTEasy Reactive, a novel way to serve HTTP API in Quarkus. Since its introduction, RESTEasy Reactive adoption has been quite good, and we plan to make it the default approach to implement HTTP API shortly. But, wait a minute, what does that mean...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/nCCiwUoAHPg" height="1" width="1" alt=""/&gt;</content><dc:creator>Clement Escoffier</dc:creator><feedburner:origLink>https://quarkus.io/blog/resteasy-reactive-smart-dispatch/</feedburner:origLink></entry><entry><title type="html">DMN editor – Contributors Guide – Part 2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/6MHEsAWChgk/dmn-editor-contributors-guide-part-2.html" /><author><name>Guilherme Carreiro</name></author><id>https://blog.kie.org/2021/08/dmn-editor-contributors-guide-part-2.html</id><updated>2021-08-24T11:22:05Z</updated><content type="html">If you’re reading this, probably you’ve already thought about contributing to an open-source project. However, projects generally have some learning curve, which may intimidate newcomers. We do not want that feeling for the DMN editor! So, this is the second of a series of posts that will quickly empower you to contribute to the DMN editor and other Kogito components. Are you excited too? So, this guide is for you! &#x1f603; Today, we’re going to walk through our TypeScript/React components. You’ll learn how to create a new one and modify an existing feature. OVERVIEW Currently, the DMN and the BPMN editors are Java/GWT-based. However, we’re writing new features based on our new stack powered by TypeScript and React. Check how we’re embedding new components into the editors: As we can see in the diagram above, we may have many Components based on React or any other framework. They are entirely uncoupled from the host application (DMN editor) and may be re-used anywhere. Each Editor (DMN or BPMN) has its Loader, which is responsible for grouping all components and teaching how the host application must render each one. Loaders may also include features like compressing, lazy loading, and versioning. CREATING YOUR REACT COMPONENT Okay! But, how can you create those blue boxes? In other words, how can you create new components? Is it difficult? No! You can rely on the yarn new-component command (in the module). It auto-generates all required boilerplates to build a new component, which is not too much, but we created this command to encourage valuable conventions (like component showcases). Check this complete tutorial: . It has all the steps, from creating the component to embedding it in the GWT editor. Now you can create your component by relying on its showcase. So, you don’t need to run the whole editor test, develop, and validate it (if you want to know more about how showcases work, check written by Valentino &#x1f609;). TESTING YOUR COMPONENT IN THE EDITOR At this point, your component is probably running into the DMN editor (if it’s not, you may follow the tutorial above). Still, sometimes we need to connect the dots, integrate everything and see your component in action on GWT by running it in the development mode. For this kind of scenario, you need to wire both worlds. Thus, you’ll be able to perform changes in the GWT or React side and see the changes without restarting the DMN editor web app. Here you may check all steps for wiring your components and the GWT editor: . CHALLENGE TIME! Now you know how React components work in the context of the DMN editor! If you find any problems following the tutorials above, I recorded this video walking through both tutorials: Would you like to start playing with React and real-world challenges? Currently, we have the and the epics with various ideas. If you’d like to start contributing, please reach out the DMN tooling team in the #tooling team on ! &#x1f60a; The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/6MHEsAWChgk" height="1" width="1" alt=""/&gt;</content><dc:creator>Guilherme Carreiro</dc:creator><feedburner:origLink>https://blog.kie.org/2021/08/dmn-editor-contributors-guide-part-2.html</feedburner:origLink></entry><entry><title>Game telemetry with Kafka Streams and Quarkus, Part 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/uX-S72p8EXc/game-telemetry-kafka-streams-and-quarkus-part-1" /><author><name>Evan Shortiss</name></author><id>eef64f30-45cd-43da-915e-2c299dd091c7</id><updated>2021-08-24T07:00:00Z</updated><published>2021-08-24T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; makes it possible to run a variety of analytics on large-scale data. This is the first half of a two-part article that employs one of Kafka's most popular projects, the &lt;a href="https://kafka.apache.org/documentation/streams/"&gt;Kafka Streams API&lt;/a&gt;, to analyze data from an online interactive game. Our example uses the Kafka Streams API along with the following Red Hat technologies:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/overview"&gt;Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt; is a fully hosted and managed Apache Kafka service.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.openshift.com/products/application-services"&gt;Red Hat OpenShift Application Services&lt;/a&gt; simplifies provisioning and interaction with managed Kafka clusters, and integration with your applications.&lt;/li&gt; &lt;li&gt;The &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; lets you deploy and test applications quickly.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The two-part article is based on a demonstration from &lt;a href="https://www.redhat.com/en/summit"&gt;Red Hat Summit&lt;/a&gt; 2021. This first part sets up the environment for analytics, and the second part runs the analytics along with replaying games from saved data.&lt;/p&gt; &lt;h2&gt;Why do game data analysis?&lt;/h2&gt; &lt;p&gt;Sources indicate that there are approximately three billion active gamers around the globe. Our pocket-sized supercomputers and their high-speed internet connections have made gaming more accessible than it has ever been. These factors also make data generated during gameplay more accessible and enable developers to constantly improve games after their release. This continuous iteration requires data-driven decision-making that's based on events and telemetry captured during gameplay.&lt;/p&gt; &lt;p&gt;According to &lt;a href="https://steamcharts.com/"&gt;steamcharts.com&lt;/a&gt;, the most popular games often have up to one million concurrent players online—and that’s just the PC versions of those games! That number of players will generate enormous amounts of valuable telemetry data. How can development teams ingest such large volumes of data and put it to good use?&lt;/p&gt; &lt;h2&gt;Uses of game telemetry data&lt;/h2&gt; &lt;p&gt;A practical example can help solidify the value of game telemetry data. The developers of a competitive online FPS (first-person shooter) game could send an enormous amount of telemetry events related to player activity. Some simple events and data might include:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The player’s location in the game world, recorded every &lt;em&gt;N&lt;/em&gt; seconds.&lt;/li&gt; &lt;li&gt;Weapon choices and changes.&lt;/li&gt; &lt;li&gt;Each time the player fires a shot.&lt;/li&gt; &lt;li&gt;Each time a player successfully hits an opponent.&lt;/li&gt; &lt;li&gt;Items the player obtains.&lt;/li&gt; &lt;li&gt;Player wins and losses.&lt;/li&gt; &lt;li&gt;Player connection quality and approximate physical location.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Game developers could use the data in these events to determine the busy or hot spots on the game world, the popularity of specific weapons, the players' shooting accuracy, and even the accuracy of players using specific weapons.&lt;/p&gt; &lt;p&gt;Developers could use this information to make game balance adjustments. For example, if a specific weapon is consistently chosen by 50% of players and their accuracy with that weapon is higher than with other weapons, there’s a chance that the weapon is overpowered or bugged.&lt;/p&gt; &lt;p&gt;Network engineers could ingest the player ping time and location to generate Grafana dashboard and alerts, isolate problems, and reference the data when choosing new data center locations.&lt;/p&gt; &lt;p&gt;Marketers could also use the data to market power-ups or incentives to players down on their luck if the game supports microtransactions.&lt;/p&gt; &lt;h2&gt;Example and prerequisites&lt;/h2&gt; &lt;p&gt;This article shows you how to employ Red Hat OpenShift Streams for Apache Kafka with the Kafka Streams API to ingest and analyze real-time events and telemetry reported by a game server, using a practical example. Specifically, you’ll learn how to:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Use the Red Hat OpenShift Application Services CLI and OpenShift Streams for Apache Kafka to: &lt;ol&gt;&lt;li&gt;Provision &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Kafka clusters&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Manage Kafka topics.&lt;/li&gt; &lt;li&gt;Connect your OpenShift project to a managed Kafka instance.&lt;/li&gt; &lt;/ol&gt;&lt;/li&gt; &lt;li&gt;Develop a &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java application&lt;/a&gt; using the Kafka Streams API to process event data.&lt;/li&gt; &lt;li&gt;Expose HTTP endpoints to the processed data using &lt;a href="https://developers.redhat.com/products/quarkus"&gt;Quarkus&lt;/a&gt; and MicroProfile.&lt;/li&gt; &lt;li&gt;Deploy &lt;a href="topics/nodejs"&gt;Node.js&lt;/a&gt; and Java applications on Red Hat OpenShift and connect them to your OpenShift Streams for Apache Kafka cluster.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;To follow along with the examples, you’ll need:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Access to Red Hat OpenShift Streams for Apache Kafka. You can get a free account at the &lt;a href="https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/getting-started"&gt;Getting started site&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Access to Developer Sandbox. Use the &lt;strong&gt;Get started in the Sandbox&lt;/strong&gt; link on the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox welcome page&lt;/a&gt; to get access for free.&lt;/li&gt; &lt;li&gt;The Red Hat OpenShift Application Services command-line interface (CLI). Installation instructions are available &lt;a href="https://github.com/redhat-developer/app-services-guides/tree/main/rhoas-cli#installing-the-rhoas-cli"&gt;on GitHub&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;The OpenShift CLI. The tool is available at the &lt;a href="https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/"&gt;page of files for downloading&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;The Git CLI. Downloads are available at the &lt;a href="http://git-scm.com/downloads"&gt;Git download page&lt;/a&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;The demo application: Shipwars&lt;/h2&gt; &lt;p&gt;If you attended Red Hat Summit 2021 you might have already played our &lt;a href="https://arcade.redhat.com/shipwars"&gt;Shipwars game&lt;/a&gt;. This is a browser-based video game (Figure 1) that’s similar to the classic &lt;a href="https://en.wikipedia.org/wiki/Battleship_(game)"&gt;Battleship&lt;/a&gt; tabletop game, but with a smaller 5x5 board and a server-side AI opponent.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_1.png?itok=HdgpQ6FJ" width="1440" height="807" alt="The Shipwars game is a small board of squares shown in a web browser, with ships that the opponent tries to sink by clicking on squares in the board." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A player positioning ships in Shipwars. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Shipwars is a relatively simple game, unlike the complex shooter game described earlier. Despite the simplicity of Shipwars, it generates useful events for you to process. We'll focus on two specific events:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Player: Created when a player connects to the server and is assigned a generated username; for example, "Wool Pegasus" from Figure 1.&lt;/li&gt; &lt;li&gt;Attack: Sent whenever a player attacks. Each player will attack at least 13 times, because a minimum of 14 hits are required to sink all of the opponent’s ships.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;You’ll deploy the Shipwars &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; and send these events to a managed Kafka instance running on OpenShift Streams for Apache Kafka. You’ll also use Kafka Streams to process events generated by the game. This involves using Kafka Streams to:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Join data from two separate Kafka topics.&lt;/li&gt; &lt;li&gt;Create aggregations using the joined data stream.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;The join can be used to create a real-time heatmap of player shots. It is also a prerequisite for the aggregation stage.&lt;/p&gt; &lt;p&gt;The aggregations can be used to:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Create and store records of completed games with each turn in order.&lt;/li&gt; &lt;li&gt;Analyze how human players compare to their AI counterparts.&lt;/li&gt; &lt;li&gt;Continuously update your AI model.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 2 shows the overall architecture of core game services, topics in Red Hat OpenShift Streams for Apache Kafka, and the Kafka Streams topology you’ll create.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_2.jpeg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_2.jpeg?itok=bTBl-nml" width="1440" height="953" alt="The architecture of this example contains a game client communicating with a server, which sends data through Red Hat OpenShift Streams for Apache Kafka to Kafka Streams applications." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Architecture of this example, including the environment for the application and the Kafka Streams topology. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Deploying the core Shipwars services on the Developer Sandbox&lt;/h2&gt; &lt;p&gt;The README file in Red Hat's &lt;a href="https://github.com/redhat-gamedev/shipwars-deployment"&gt;Shipwars deployment repository&lt;/a&gt; can help you quickly deploy the game.&lt;/p&gt; &lt;p&gt;The first step is to deploy Shipwars on the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox&lt;/a&gt;. Shipwars can run without Kafka integration, so you’ll add the Kafka integration after the core game microservices are running.&lt;/p&gt; &lt;p&gt;Get started by accessing the Developer Sandbox. Once you're logged in, you should see two empty projects (namespaces). For example, my projects are &lt;code&gt;eshortis-dev&lt;/code&gt; and &lt;code&gt;eshortis-stage&lt;/code&gt;, as shown in Figure 3. I use the &lt;code&gt;dev&lt;/code&gt; namespace throughout this two-part article.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_3.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_3.jpg?itok=93oILfJb" width="1440" height="878" alt="The OpenShift Developer Sandbox makes two projects available to each user, including a development project." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Projects that are automatically available in Developer Sandbox. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The deployment process for Shipwars uses the OpenShift CLI. Do the following to obtain the OpenShift CLl login command and token:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Click your username in the top-right corner of the OpenShift Sandbox UI.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Copy Login Command&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Select the &lt;strong&gt;DevSandbox&lt;/strong&gt; login option when prompted.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Display Token&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Copy and paste the displayed login command into your terminal.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;After a successful login, the OpenShift CLI prints your available projects.&lt;/p&gt; &lt;p&gt;Next, use the &lt;code&gt;git clone&lt;/code&gt; command to clone the &lt;a href="https://github.com/redhat-gamedev/shipwars-deployment"&gt;shipwars-deployment&lt;/a&gt; repository into your workspace. Figure 4 shows both the OpenShift CLI and Git CLI commands.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_4.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_4.jpg?itok=iwrUUf2b" width="1440" height="878" alt="An "oc login" command connects to OpenShift, and a subsequent "git clone" command installs the Shipwars application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Use of the OpenShift CLI login and a "git clone" command. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A &lt;a href="https://github.com/redhat-gamedev/shipwars-deployment"&gt;script&lt;/a&gt; is included to deploy Shipwars. This is a straightforward script that applies YAML files so you can get to the Kafka content more quickly:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ git clone https://github.com/redhat-gamedev/shipwars-deployment $ cd shipwars-deployment/openshift $ NAMESPACE=eshortis-dev ./deploy.game.sh&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;NAMESPACE&lt;/code&gt; variable must be set to a valid namespace in your Developer Sandbox. The &lt;code&gt;eshortis-dev&lt;/code&gt; value used here is an example, and must be replaced with the equivalent for your username, such as &lt;code&gt;myusername-dev&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The script prints the resource types as it creates them. Once it is finished, you can view the deployed services in the OpenShift topology view. You can also click the &lt;strong&gt;Open URL&lt;/strong&gt; link on the NGINX service, as shown in Figure 5, to view and play the Shipwars game against an AI opponent.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_5.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_5.jpg?itok=_EvSllFf" width="1440" height="878" alt="The OpenShift Topology View shows that Shipwars consists of servers and a client." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: The OpenShift topology view showing the Shipwars core services. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating a Kafka instance and topics&lt;/h2&gt; &lt;p&gt;If you’re not familiar with the basics of OpenShift Streams for Apache Kafka, consider reviewing this introductory article: &lt;a href="https://developers.redhat.com/articles/2021/07/07/getting-started-red-hat-openshift-streams-apache-kafka"&gt;Getting started with Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt;. It covers the basics of creating Kafka instances, topics, and service accounts.&lt;/p&gt; &lt;p&gt;In this article, we use the &lt;a href="https://www.openshift.com/products/application-services"&gt;Red Hat OpenShift Application Services&lt;/a&gt; CLI, &lt;code&gt;rhoas&lt;/code&gt;, to manage the creation of everything needed to integrate OpenShift Streams for Apache Kafka with the Shipwars game server you deployed on the Developer Sandbox.&lt;/p&gt; &lt;p&gt;To get started, log in to your &lt;a href="https://cloud.redhat.com/"&gt;cloud.redhat.com&lt;/a&gt; account and create a Kafka instance using the following commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# Login using the browser flow rhoas login # Create a kafka instance rhoas kafka create shipwars&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;kafka create&lt;/code&gt; command will complete within a few seconds, but the Kafka instance won’t be ready at this point. Wait for two or three minutes, then issue a &lt;code&gt;rhoas kafka list&lt;/code&gt; command. This lists your Kafka instances and their status. You can continue with the procedure in this article when the &lt;code&gt;shipwars&lt;/code&gt; instance status is "ready," as shown in Figure 6.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_6.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_6.jpg?itok=WjDLLpA2" width="1440" height="878" alt="The output from a "rhoas kafka list" command shows a managed Kafka instance in OpenShift with a status of "ready."" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: The managed Kafka instance in OpenShift is ready. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The Red Hat OpenShift Application Services CLI allows you to select a Kafka instance as the context for future commands. Select your newly created &lt;code&gt;shipwars&lt;/code&gt; instance using the &lt;code&gt;rhoas kafka use&lt;/code&gt; command, then create the necessary topics as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# Choose the kafka instance to create topics in rhoas kafka use # Create necessary game event topics rhoas kafka topic create shipwars-matches --partitions 3 rhoas kafka topic create shipwars-players --partitions 3 rhoas kafka topic create shipwars-attacks --partitions 3 rhoas kafka topic create shipwars-bonuses --partitions 3 rhoas kafka topic create shipwars-results --partitions 3 # Create topics used by Kafka Streams rhoas kafka topic create shipwars-attacks-lite --partitions 3 rhoas kafka topic create shipwars-streams-shots-aggregate --partitions 3 rhoas kafka topic create shipwars-streams-matches-aggregate --partitions 3&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The topic configuration is printed in JSON format after each topic is created, as shown in Figure 7. The only configuration that you’ve explicitly set for your topics is the partition count; other values use sensible defaults.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_7.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_7.jpg?itok=EXhZCFN6" width="1440" height="878" alt="Kafka topics are created in a managed Kafka instance in OpenShift." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Selecting a managed Kafka instance and creating Kafka topics. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Connecting to the Shipwars game server&lt;/h2&gt; &lt;p&gt;At this point, you’ve obtained a managed Kafka instance and configured it with the topics required by the Shipwars game. The next step is to configure the Node.js &lt;code&gt;shipwars-game-server&lt;/code&gt; to connect to your topics and send events to them. This is a two-step process.&lt;/p&gt; &lt;p&gt;First, you need to link your OpenShift project to your managed Kafka instance. You can do this by issuing the &lt;code&gt;rhoas cluster connect&lt;/code&gt; command. The command starts a guided process that will ask you to confirm the project and managed Kafka instance being linked, and request you to provide a token obtained from a &lt;a href="https://cloud.redhat.com/openshift/token"&gt;cloud.redhat.com/openshift/token&lt;/a&gt; as shown in Figure 8.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_8.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_8.jpg?itok=BDK7fUA0" width="1440" height="878" alt="An OpenShift token allows a project to be connected to a managed Kafka instance." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Associating a managed Kafka instance with an OpenShift project. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;This process creates the following resources in the target OpenShift project:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;A &lt;code&gt;KafkaConnection&lt;/code&gt; custom resource that contains information such as bootstrap server URL and SASL mechanism.&lt;/li&gt; &lt;li&gt;A &lt;code&gt;Secret&lt;/code&gt; that contains the service account credentials for connecting to the Kafka instance via SASL SSL.&lt;/li&gt; &lt;li&gt;A &lt;code&gt;Secret&lt;/code&gt; that contains your cloud.redhat.com token.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Next, run the &lt;code&gt;rhoas cluster bind&lt;/code&gt; command. This guides you through the process of creating a &lt;code&gt;ServiceBinding&lt;/code&gt; and updates the &lt;code&gt;shipwars-game-server&lt;/code&gt; &lt;code&gt;Deployment&lt;/code&gt; with the credentials required to connect to your managed Kafka instance.&lt;/p&gt; &lt;p&gt;Once the binding process has completed, a new &lt;code&gt;Secret&lt;/code&gt; is generated and mounted into a new pod of the &lt;code&gt;shipwars-game-server&lt;/code&gt; &lt;code&gt;Deployment&lt;/code&gt;. You can explore the contents of this secret using the OpenShift CLI or UI, as shown in Figure 9.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_9.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_9.jpg?itok=tKCyOGh2" width="1440" height="878" alt="A Secrets screen in the OpenShift console shows details about the generated secret that contains managed Kafka connection information." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: A generated Secret that contains managed Kafka connection information. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Lastly, you can confirm that the Node.js-based &lt;code&gt;shipwars-game-server&lt;/code&gt; has connected to your managed Kafka instance by viewing its logs. Find the logs by selecting the &lt;code&gt;shipwars-game-server&lt;/code&gt; from the OpenShift topology view, selecting the &lt;strong&gt;Resources&lt;/strong&gt; tab, and clicking the &lt;strong&gt;View logs&lt;/strong&gt; link. The startup logs should contain a message stating that a Kafka producer has connected to the managed Kafka instance bootstrap server URL, as shown in Figure 10.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift_kafka_1_10.jpg" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/openshift_kafka_1_10.jpg?itok=73EP3tJl" width="1440" height="878" alt="The logs from the Shipwars game server show that a Kafka producer has connected to a managed Kafka instance deployed on OpenShift Streams for Apache Kafka." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: The Kafka producer has connected to the managed Kafka instance. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion to Part 1&lt;/h2&gt; &lt;p&gt;In this first half of the article, we have set up our game and our environment for analytics. In the second half, we'll run analytics and replay some games. For now, you can verify that game events are being streamed to your managed Kafka instance using a tool such as &lt;a href="https://github.com/edenhill/kafkacat"&gt;kafkacat&lt;/a&gt;. As an example, the following command outputs the contents of the &lt;code&gt;shipwars-attacks&lt;/code&gt; topic as it receives events from the &lt;code&gt;shipwars-game-server&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ kafkacat -t shipwars-attacks-b $KAFKA_BOOTSTRAP_SERVER \ -X sasl.mechanisms=PLAIN \ -X security.protocol=SASL_SSL \ -X sasl.username=$CLIENT_ID \ -X sasl.password=$CLIENT_SECRET -K " / " -C &lt;/code&gt;&lt;/pre&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/08/24/game-telemetry-kafka-streams-and-quarkus-part-1" title="Game telemetry with Kafka Streams and Quarkus, Part 1"&gt;Game telemetry with Kafka Streams and Quarkus, Part 1&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/uX-S72p8EXc" height="1" width="1" alt=""/&gt;</summary><dc:creator>Evan Shortiss</dc:creator><dc:date>2021-08-24T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/08/24/game-telemetry-kafka-streams-and-quarkus-part-1</feedburner:origLink></entry><entry><title type="html">Kogito 1.10.0 released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/mWDjcSpx7NU/kogito-1-10-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2021/08/kogito-1-10-0-released.html</id><updated>2021-08-24T06:24:30Z</updated><content type="html">We are glad to announce that the Kogito 1.10.0 release is now available! This goes hand in hand with and , . From a feature point of view, we included a series of new features and bug fixes, including: * Introducing the new . Now you can fine tune your Kogito Spring Boot project with the specific starter * – ConfigMap required ownerReference as controller * – Kogito Operator Data-Index Unable to connect to Infinispan Instance * – It is now possible to disable the generation of REST endpoints via properties. For example kogito.generate.rest=false disables the generation of all the endpoints while kogito.generate.rest.decisions=false disables the generation of the DMN endpoints (same apply to processes, rules and predictions) BREAKING CHANGES * The usage of kogito.persistence.postgresql.connection.uri has been discontinued in this release when using the Postgresql addon for Quarkus. The same configuration can now be achieved by using the . For more details head to the complete. All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found. * Kogito images are available on. * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.12.0 artifacts are available at the. A detailed changelog for 1.10.0 can be found in. New to Kogito? Check out our website. Click the "Get Started" button. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/mWDjcSpx7NU" height="1" width="1" alt=""/&gt;</content><dc:creator>Cristiano Nicolai</dc:creator><feedburner:origLink>https://blog.kie.org/2021/08/kogito-1-10-0-released.html</feedburner:origLink></entry><entry><title type="html">Deploy decisions to DMN Developer Sandbox</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/qPxtcQnOdm8/deploy-decisions-to-dmn-developer-sandbox.html" /><author><name>Guilherme Caponetto</name></author><id>https://blog.kie.org/2021/08/deploy-decisions-to-dmn-developer-sandbox.html</id><updated>2021-08-23T18:04:16Z</updated><content type="html">In early 2021, Red Hat introduced the Developer Sandbox for Red Hat OpenShift. On top of that, we built the DMN Developer Sandbox, which makes deploying decision services easy for developers, and this is now live at as part of the Kogito Tooling 0.12.0 release. Let’s check out how the DMN Developer Sandbox works in this post! Photo by on  If you are not familiar with the Developer Sandbox for Red Hat OpenShift, here is a quote from the that pretty much sums up all its capabilities: The sandbox provides you with a private OpenShift environment in a shared, multi-tenant OpenShift cluster that is pre-configured with a set of developer tools. You can easily create containers from your source code or Dockerfile, build new applications using the samples and stacks provided, add services such as databases from our templates catalog, deploy Helm charts, and much more. Discover the rich capabilities of the full developer experience on OpenShift with the sandbox. In addition, I recommend the KIE Live #35, which shows how to stream decisions using both the Developer Sandbox for Red Hat OpenShift and the Red Hat OpenShift Streams for Apache Kafka. Now, let’s talk about the DMN Developer Sandbox. Simply put, the DMN Developer Sandbox allows you to deploy decision models to the Developer Sandbox for Red Hat OpenShift. Here is what happens behind the scenes when you deploy your DMN: * We prepared a base docker image containing an empty Kogito project, a form web app to be loaded up, and tools to build everything up; * All resources associated with the deployment are created for you in your instance, including ImageStream, Service, Route, BuildConfig, Build, and Deployment. * The DMN that is being deployed is placed inside the Kogito project that is in the base image and this project is built as part of a Dockerfile; * Once the project is built up, the generated Quarkus app is started up and exposed through the newly created Route in your instance. Important: The DMN Developer Sandbox is intended to be used during development, so users should not use the deployed DMN services in production or for any type of business-critical workloads. STEP BY STEP: HOW TO DEPLOY YOUR DECISION MODEL 1-) GO TO  You will notice that the toolbar has slightly changed. In the highlighted red rectangle, you will find the KIE Tooling Extended Services status icon, the DMN Developer Sandbox dropdown (as Deploy), the DMN Runner button (as Run), and the Save button. Check out post to learn more about the DMN Runner. 2-) INSTALL THE KIE TOOLING EXTENDED SERVICES Since both DMN Runner and DMN Developer Sandbox features depend on having the KIE Tooling Extended Services running, you need to install it. To do so, click on the Deploy dropdown or on the Run button, and follow the steps that will be presented to you. Once the KIE Tooling Extended Services is running, the status icon will turn green. Note: You need to install the 0.12.0 version of the KIE Tooling Extended Services even if you are using an older version. KIE Tooling Extended Services running. 3-) SETUP YOUR DEVELOPER SANDBOX INFORMATION Click on the Deploy dropdown and then Setup. Since this is the first time we are setting this up, let’s use the guided wizard instead. In the popup, click on the Configure through the guided wizard instead link. Open the guided wizard to configure the Developer Sandbox information. In the first step of the wizard, you need to set up your Developer Sandbox for Red Hat OpenShift instance before proceeding with the rest of the steps. As you will be instructed in the wizard, access the page and create your instance. Developer Sandbox for Red Hat OpenShift fresh instance. Once your instance is ready, you can pick up your username in the upper-right corner and place it in the first step of the wizard. This information is necessary for locating your namespaces (or projects). Note: You receive two namespaces (or projects) when you create your instance, namely username-dev and username-stage. However, we always use the username-dev for the deployments on this first release of the DMN Dev Sandbox. Fill up the first step with the username. In the second step of the wizard, you need to provide some more information about your newly created instance. Following the instructions provided in the wizard, you will reach this page in your instance: Get the host and token information. On this page, you need to copy the –server and –token information, and paste them in the second step of the wizard. This information is necessary for establishing a connection with your instance. Note: Do not share your personal token with anyone. Fill up the second step with host and token. In the next and last step, you should see that your connection has been successfully established using the three pieces of information that you provided (username, host, and token). Connection successfully established in the last step of the wizard. You can then Deploy now or Continue editing. Since our decision model is not ready yet, I will go with Continue editing. Now that everything is set up, you are able to deploy your decision models and check the other deployments that you have done. You will also notice a blue bar at the bottom of the Deploy dropdown button, indicating that your instance is connected. DMN Developer Sandbox connected. 4-) DESIGN YOUR DECISION MODEL In this tutorial, I will be using the Traffic Violation decision model. The cool thing is that, while authoring my decision model, I can use the DMN Runner to be sure that everything is working as expected. Traffic Violation decision model. 5-) DEPLOY YOUR DECISION MODEL Once your decision model is ready, you can go ahead and deploy it. Keep in mind that each deployment takes a few minutes (usually) and it is immutable, i.e., you will need to trigger a new deployment if you make changes in your decision model. Once done, you will find your deployment in your username-dev namespace. Deploy the model and see the deployment in progress. You will see a green indicator icon once your deployment is up and running. Note: The deployment will fail if your decision model contains errors. 6-) CHECK OUT YOUR DEPLOYED DECISION MODEL Once your deployment is up and running, you can access it through the Deploy dropdown. When you do so, a new page will be open on your browser containing the form associated with your model for you to test and share the URL with others. Open the form associated with the deployed decision model. Test the deployed decision model. You can also access the Swagger UI associated with the deployed decision model and share the URL with others. Access the Swagger UI associated with the deployed decision model. Lastly, you can even open your decision model on and share the URL with others. SOME THINGS TO KEEP IN MIND * Your Developer Sandbox for Red Hat OpenShift instance needs to be renewed every 30 days. It means that, after 30 days, all your data will be deleted. * Tokens need to be renewed daily. * Limit of 10 deployments. * Deployments stay up for 8 hours but you can scale them up again when they go down. I would like to recommend the KIE Live #40 if you want to see more details and a full end-to-end demonstration on how to use the DMN Developer Sandbox. And that’s all for today. Thanks for reading! &#x1f603; The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/qPxtcQnOdm8" height="1" width="1" alt=""/&gt;</content><dc:creator>Guilherme Caponetto</dc:creator><feedburner:origLink>https://blog.kie.org/2021/08/deploy-decisions-to-dmn-developer-sandbox.html</feedburner:origLink></entry><entry><title type="html">Kogito Tooling 0.12.0 Released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/V07c2979zfU/kogito-tooling-0-12-0-released.html" /><author><name>Eder Ignatowicz</name></author><id>http://feeds.athico.com/~r/droolsatom/~3/n_QbD0xh5_U/kogito-tooling-0-12-0-released.html</id><updated>2021-08-23T05:00:00Z</updated><content type="html">We have just launched a fresh new Kogito Tooling release! &#x1f389; On the 0.12.0 , we made a lot of improvements and bug fixes. We are also happy to announce that this release marks the first iteration of our ‘DMN deploy on OpenShift’ feature, and also we have a lot of improvements on our DMN and BPMN Editors. This post will give a quick overview of this . I hope you enjoy it! DEPLOY DECISIONS TO DMN DEVELOPER SANDBOX ON DMN.NEW We just launched in our dmn.new environment a feature that allows you to quickly deploy decision models to the Developer Sandbox for Red Hat OpenShift. This feature is super cool, and I invite you to give it a try. You can also check more details on this blog . DMN NODES ARE NOT CREATED ON TOP OF THE SELECTED NODE DMN diagrams are generally vertical (whereas BPMN is horizontal). When adding a “Decision Node” from a “DMN Input Data,” for better usability, now the nodes are created on top of the selected node. DMN SUPPORT FOR BEND-POINTS ON CONNECTORS We also added support for bend-points on the DMN diagram that are pretty useful, especially on Complex DMN diagrams. See this for more details. LINE SPLICING FOR BPMN AND DMN EDITORS Line splicing is a new feature that allows dropping an existing node on top of a connector and automatically split it into two new connectors. This was included in both our DMN and BPMN editors. Soon we will publish a blog post with a detailed description of this feature. RESIZE CONTROL POINTS IMPROVEMENTS We made many improvements on resizing control points for our BPMN and DMN editor, including changing the resize icon and modifying how magnets react on a resize. SUPPORT FOR PROCESS METADATA ATTRIBUTES We also added a new AdvancedData that allows users to add generic metadata to all node types and event types in the BPMN editor. [![Metadata](/assets/2021/metatada.png “Metadata * – BPMN Editor – Support for node/events metadata attributes * – DMN Developer Sandbox for Red Hat OpenShift * – DMN target position is not stored * – Stunner – Task Resize option doesn’t show up * – [DMN Editor] Ctrl-B always converts field to structure and nests * – VSCode DMN, BPMN editor – creating connection can’t be cancelled easily * – Stunner – Resize Icon remains displayed * – BPMN Editor – Cannot import some processes * – DMN Runner – Wizard step for running * – BPMN Editor – Marshallers encoding issues * – [Test Scenario] No effects when assigning a not-expression Simple Type column to expression type (and viceversa) * – BPMN Editor – Moving connector’s bendpoints results on erros in the console * – [Stunner] bend point modification causes diagram inaccessible * – Stunner – Line splicing * – Implement E2E automation for Reuse of Data Types in BPMN Designer * – Verify support for node/event metadata attribues feature * – Stunner – first POC of new marshallers * – [DMN Designer] When users create a node by using a shortcut, it’s not created above * – Update vscode-extension-tester to 4.1.0 * – [DMN/BPMN] Wired web apps – Fix doc screenshot * – Implement – designs for orthogonal lines between diagram nodes * – [Test Scenario] – Errors when executing models using imported inputs and/or decisions nodes * – Stunner – Make new nodes editable automatically * – Stunner – Resize control points – Fixes &amp;amp; UX improvements * – [DMN Designer] Add support for bend-points on connectors * – [Stunner] Lienzo – Migration to native interfaces * – Stunner – Alignment helpers missing during node resize * – Stunner – WID files with comments and Imports can’t be loaded FURTHER READING/WATCHING We had some excellent blog posts on Kie Blog that I recommend you read: * , by Eder Ignatowicz; * , by Manaswini Das; * , by Daniel José dos Santos; * , by Luiz Motta; * , by Manaswini Das; * , by Valentino Pellegrino; * , by Guilherme Caponetto. We also presented in some Kie Lives: * , by Tiago Bento; * , by Yeser Amer; THANK YOU TO EVERYONE INVOLVED! I would like to thank everyone involved with this release, from the excellent KIE Tooling Engineers to the lifesavers QEs and the UX people that help us look awesome! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/V07c2979zfU" height="1" width="1" alt=""/&gt;</content><dc:creator>Eder Ignatowicz</dc:creator><feedburner:origLink>http://feeds.athico.com/~r/droolsatom/~3/n_QbD0xh5_U/kogito-tooling-0-12-0-released.html</feedburner:origLink></entry><entry><title>Composable software catalogs on Kubernetes: An easier way to update containerized applications</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Qu9uHZyp9gE/composable-software-catalogs-kubernetes-easier-way-update-containerized" /><author><name>David Festal</name></author><id>d42b5c6a-cc3d-45ed-9bd9-ac7ffb22b852</id><updated>2021-08-20T07:00:00Z</updated><published>2021-08-20T07:00:00Z</published><summary type="html">&lt;p&gt;Recently, I've been experimenting with how to build and use composable software catalogs on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. Similar to &lt;a href="https://developers.redhat.com/products/softwarecollections/overview"&gt;Red Hat Software Collections&lt;/a&gt; for &lt;a href="products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt;, but adapted for a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; context, composable software catalogs let developers add tooling without building a new container image.&lt;/p&gt; &lt;p&gt;This article explains how composable software catalogs use existing container technologies to build on the Software Collections model, and how they can potentially make more options available to container users, simplify builds, and reduce container image sizes.&lt;/p&gt; &lt;h2&gt;Software Collections in a containerized world&lt;/h2&gt; &lt;p&gt;To understand the need for composable software catalogs, let's go back in time a bit.&lt;/p&gt; &lt;p&gt;Do you remember &lt;a href="https://www.softwarecollections.org/en/"&gt;Software Collections&lt;/a&gt;? The motto of this project, backed by Red Hat, was: &lt;em&gt;All versions of any software on your system. Together.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;The promise was to build, install, and use multiple versions of software on the same system, without affecting system-wide installed packages. The key point was to create this multifold environment without affecting system-wide installed packages. In other words, it provided additional tooling without any change to the current state of the operating system as a whole. Software Collections worked well in its time, even winning a Top Innovator Award at DeveloperWeek 2014.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Red Hat Software Collections is available for Red Hat Enterprise Linux 7 and earlier supported releases. Starting with Red Hat Enterprise Linux 8, &lt;a href="https://access.redhat.com/support/policy/updates/rhscl"&gt;application streams replace Software Collections&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;A new landscape but the same need&lt;/h3&gt; &lt;p&gt;Things have changed since 2014. The container revolution popped up and brought features such as execution isolation, file system layering, and volume mounting. This solved quite a lot of problems. Thanks to containers, one could say that the old Software Collections became obsolete. But container orchestrators came along, as well (I'll stick to &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; in this article). Deploying workloads as containers inside pods became standard. Finally, even workloads such as build pipelines or IDEs moved to the cloud and also ran inside containers.&lt;/p&gt; &lt;p&gt;But containers themselves have limitations. At some point, developers start experiencing the same type of need inside containers that Software Collections once tried to solve at the operating system level.&lt;/p&gt; &lt;h3&gt;Why revisit Software Collections?&lt;/h3&gt; &lt;p&gt;A &lt;em&gt;container&lt;/em&gt; is based on a single &lt;em&gt;container image&lt;/em&gt;, which is like a template for multiple identical containers. And a container image is optionally based on a single &lt;em&gt;container image&lt;/em&gt; &lt;em&gt;parent&lt;/em&gt;. To build a container image, you typically start from a basic operating system image. Then you add layers one by one, each on top of the previous one, to provide each additional tool or feature that you need in your container. Thus, each container is based on an image whose layers are overlays in a single inheritance tree. A container image is a snapshot of the current state of an operating system at a given point in time.&lt;/p&gt; &lt;p&gt;For container images, the old promise of Software Collections would be useful. In a container context, the goal of providing additional tooling &lt;em&gt;without any change to the current state of the operating system&lt;/em&gt; simply becomes &lt;em&gt;without having to build a new container image&lt;/em&gt;.&lt;/p&gt; &lt;h3&gt;A combinatorial explosion of components&lt;/h3&gt; &lt;p&gt;Let's take an example:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;I'd like to run a &lt;a href="https://developers.redhat.com/products/quarkus"&gt;Quarkus&lt;/a&gt; application—let's say the &lt;a href="https://github.com/quarkusio/quarkus-quickstarts/tree/master/getting-started"&gt;getting started example&lt;/a&gt;—directly from source code, in development mode. I will need at least a JDK version and a Maven version on top of the base operating system.&lt;/li&gt; &lt;li&gt;I'd also like to test the application with the widest available range of versions and flavors of the JDK, Maven, and the base operating system.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;For each combination of the possible variants for those three components (JDK, Maven, and operating system), I would need to build a dedicated container image. And what if I also wanted to test with as many Gradle versions as possible? Not to mention including the native build use case, which requires GraalVM. Now imagine the combinatorial explosion that will occur if I decide to also include arbitrary versions of all my preferred tools.&lt;/p&gt; &lt;h3&gt;Inheritance versus composition&lt;/h3&gt; &lt;p&gt;The current manner of building containers limits us to a &lt;em&gt;single-inheritance model &lt;/em&gt;when what we need is &lt;em&gt;composition&lt;/em&gt;. Sometimes it would be great to be able to compose additional features or tools inside a container, without having to build a new container image. In fact, we just need to &lt;em&gt;compose container images&lt;/em&gt; at runtime. Obviously, allowing that in full generality seems tricky (if not impossible) to implement, at least given the current state of Kubernetes and containers. But what about a more limited case where we would only inject external self-contained tooling or read-only data into an existing container?&lt;/p&gt; &lt;h2&gt;Toward composable software catalogs on Kubernetes&lt;/h2&gt; &lt;p&gt;Injecting external self-contained tooling or read-only data into a container at runtime would obviously be particularly relevant if you think of things such as &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt;, Maven, Gradle, even &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;, NPM, Typescript, and the growing number of self-contained &lt;a href="https://developers.redhat.com/topics/go"&gt;Go&lt;/a&gt; utilities like Kubectl and Helm, as well as the Knative or Tekton CLI tools. None of them requires an "installation" process, strictly speaking. In order to start using them on most &lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; variants of a given platform, you need only to download and extract them.&lt;/p&gt; &lt;h3&gt;Combining two container technologies&lt;/h3&gt; &lt;p&gt;Now let's introduce two container technologies that will allow us to implement this tool injection at runtime:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/"&gt;Container Storage Interface (CSI)&lt;/a&gt;, and more specifically &lt;a href="https://kubernetes.io/blog/2020/01/21/csi-ephemeral-inline-volumes/"&gt;CSI Inline Ephemeral Volumes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://buildah.io/"&gt;Buildah&lt;/a&gt; containers&lt;/li&gt; &lt;/ul&gt;&lt;h4&gt;Container Storage Interface&lt;/h4&gt; &lt;p&gt;According to the &lt;a href="https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/#why-csi"&gt;Kubernetes documentation&lt;/a&gt;:&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;em&gt;CSI was developed as a standard for exposing arbitrary block and file storage storage systems to containerized workloads on Container Orchestration Systems (COs) like Kubernetes. With the adoption of the Container Storage Interface, the Kubernetes volume layer becomes truly extensible. Using CSI, third-party storage providers can write and deploy plugins exposing new storage systems in Kubernetes without ever having to touch the core Kubernetes code. This gives Kubernetes users more options for storage and makes the system more secure and reliable.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;CSI opens many doors to implementing and integrating storage solutions into Kubernetes. On top of that, the &lt;a href="https://kubernetes.io/blog/2020/01/21/csi-ephemeral-inline-volumes/"&gt;CSI Ephemeral Inline Volumes&lt;/a&gt; feature, still in beta, for now, allows you to specify a CSI volume, along with its parameters, directly in the pod spec, and only there. This is perfect to allow references, directly inside the pod, to the name of a tool to inject into pod containers.&lt;/p&gt; &lt;h4&gt;Buildah containers&lt;/h4&gt; &lt;p&gt;The &lt;code&gt;buildah&lt;/code&gt; tool is a well-known CLI tool that facilitates building Open Container Initiative (OCI) container images. Among many other features, it provides two that are very interesting for us:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Creating a container (from an image) that is not executing any command at the start, but can be manipulated, completed, and modified to possibly create a new image from it.&lt;/li&gt; &lt;li&gt;Mounting such a container to gain access to its underlying file system.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Buildah containers as CSI volumes&lt;/h2&gt; &lt;p&gt;The first attempt at combining CSI and &lt;code&gt;buildah&lt;/code&gt; started as a prototype example by the Kubernetes-CSI contributors, &lt;a href="https://github.com/kubernetes-csi/csi-driver-image-populator"&gt;csi-driver-image-populator&lt;/a&gt;. It was my main inspiration for the work shown in this article.&lt;/p&gt; &lt;p&gt;Providing a very lightweight and simple CSI driver, with the &lt;code&gt;image.csi.k8s.io&lt;/code&gt; identifier, &lt;code&gt;csi-driver-image-populator&lt;/code&gt; allows container images to be mounted as volumes. Deployed with a DaemonSet, the driver runs on each worker node of the Kubernetes cluster and waits for volume-mount requests. In the following example, a container image reference is specified in the pod as a parameter of the &lt;code&gt;image.csi.k8s.io&lt;/code&gt; CSI volume. Using &lt;code&gt;buildah&lt;/code&gt;, the corresponding CSI driver pulls the image, creates a container from it, and mounts its file system. The &lt;code&gt;buildah&lt;/code&gt; container filesystem is thus available to mount directly as a pod volume. Finally, the pod containers can reference this pod volume and use it:&lt;/p&gt; &lt;pre&gt; apiVersion: v1 kind: Pod metadata: name: example spec: containers: - name: main image: main-container-image volumeMount: - name: &lt;strong&gt;composed-container-volume&lt;/strong&gt; mountPath: /somewhere-to-add-the-composed-container-filesystem volumes: - name: &lt;strong&gt;composed-container-volume&lt;/strong&gt; csi: driver: image.csi.k8s.io volumeAttributes: image: &lt;strong&gt;composed-container-image&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;Upon pod removal, the pod volume is unmounted by the driver, and the &lt;code&gt;buildah&lt;/code&gt; container is removed.&lt;/p&gt; &lt;h3&gt;Adapting the CSI driver for composable software catalogs&lt;/h3&gt; &lt;p&gt;Some aspects of the &lt;code&gt;csi-driver-image-populator&lt;/code&gt; prototype do not fit our use case for composable software catalogs:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;We don't need containers in the pod to have write access to composed image volumes. The whole idea in this article is to inject &lt;em&gt;read-only&lt;/em&gt; tools and data to the pod containers through the CSI inline volumes.&lt;/li&gt; &lt;li&gt;Sticking to the read-only use case allows us to use a single &lt;code&gt;buildah&lt;/code&gt; container for a given tool image, and share its mounted file system with all the pods that reference it. The number of &lt;code&gt;buildah&lt;/code&gt; containers then depends only on the number of images provided by the software catalog on the CSI driver side. This opens the door to additional performance optimizations.&lt;/li&gt; &lt;li&gt;For both performance and security reasons, we should avoid automatically pulling the container image mounted as a CSI inline volume. Let's pull images by an external component, outside the CSI driver. And let the CSI driver expose only images that were already pulled. Thus we limit the mounted images to a well-defined list of known images. In other words, we stick to a &lt;em&gt;managed software catalog&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;Finally, for Kubernetes clusters that use an OCI-conformant container runtime (&lt;a href="https://cri-o.io/"&gt;cri-o&lt;/a&gt;, for example), we should be able to reuse images already pulled by the Kubernetes container runtime on the cluster node. This would take advantage of the image pulling capability of the Kubernetes distribution and comply with its configuration, instead of using a dedicated, distinct mechanism and configuration to pull a new image.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;To validate the idea described in this article, the changes just listed were implemented in a newly created CSI driver named &lt;a href="https://github.com/katalogos/csi-based-tool-provider"&gt;csi-based-tool-provider&lt;/a&gt;, starting from the &lt;code&gt;csi-driver-image-populator&lt;/code&gt; prototype to bootstrap the code.&lt;/p&gt; &lt;h3&gt;Providing dedicated tooling images&lt;/h3&gt; &lt;p&gt;In general, the new &lt;code&gt;csi-based-tool-provider&lt;/code&gt; driver is able to mount, as a pod read-only volume, any file system subpath of any container image. But still, it would be useful to define a typical structure for the container images that would populate such a software catalog. For "no-installation" software such as Java, which is simply delivered as an archive to extract, the most straightforward way to populate the catalog is to use "from scratch" images with the software directly extracted at the root of the filesystem. An example of a &lt;code&gt;Dockerfile&lt;/code&gt; for the &lt;a href="https://developers.redhat.com/products/openjdk/overview"&gt;OpenJDK&lt;/a&gt; 11 image would be:&lt;/p&gt; &lt;pre&gt; FROM registry.access.redhat.com/ubi8/ubi as builder WORKDIR /build RUN curl -L https://github.com/AdoptOpenJDK/openjdk11-binaries/releases/download/jdk-11.0.9.1%2B1/OpenJDK11U-jdk_x64_linux_hotspot_11.0.9.1_1.tar.gz | tar xz FROM scratch WORKDIR / COPY --from=builder /build/jdk-11.0.9.1+1 . &lt;/pre&gt; &lt;p&gt;The same holds true for the Maven distribution required by our Quarkus example mentioned earlier. Next, we'll use the Quarkus example as a proof of concept (POC).&lt;/p&gt; &lt;h2&gt;Using composable software catalogs with Quarkus&lt;/h2&gt; &lt;p&gt;Now let's come back to our Quarkus example. I want to use only an interchangeable basic operating system for my container, without building any dedicated container image. And now I can manage additional tooling through CSI volume mounts on images from my new composable software catalog.&lt;/p&gt; &lt;p&gt;The full deployment looks like this:&lt;/p&gt; &lt;pre&gt; apiVersion: apps/v1 kind: Deployment metadata: name: csi-based-tool-provider-test spec: selector: matchLabels: app: csi-based-tool-provider-test replicas: 1 template: metadata: labels: app: csi-based-tool-provider-test spec: initContainers: - name: git-sync image: k8s.gcr.io/git-sync:v3.1.3 volumeMounts: - name: source mountPath: /tmp/git env: - name: HOME value: /tmp - name: GIT_SYNC_REPO value: https://github.com/quarkusio/quarkus-quickstarts.git - name: GIT_SYNC_DEST value: quarkus-quickstarts - name: GIT_SYNC_ONE_TIME value: "true" - name: GIT_SYNC_BRANCH value: 'main' containers: - name: main image: registry.access.redhat.com/ubi8/ubi args: - ./mvnw - compile - quarkus:dev - -Dquarkus.http.host=0.0.0.0 workingDir: /src/quarkus-quickstarts/getting-started ports: - containerPort: 8080 env: - name: HOME value: /tmp - name: JAVA_HOME value: /usr/lib/jvm/jdk-11 - name: M2_HOME value: /opt/apache-maven-3.6.3 volumeMounts: - name: java mountPath: /usr/lib/jvm/jdk-11 - name: maven mountPath: /opt/apache-maven-3.6.3 - name: source mountPath: /src volumes: - name: java csi: driver: toolprovider.csi.katalogos.dev volumeAttributes: image: quay.io/dfestal/csi-tool-openjdk11u-jdk_x64_linux_hotspot_11.0.9.1_1:latest - name: maven csi: driver: toolprovider.csi.katalogos.dev volumeAttributes: image: quay.io/dfestal/csi-tool-maven-3.6.3:latest - name: source emptyDir: {} &lt;/pre&gt; &lt;p&gt;To clone the example source code from GitHub, I reuse the &lt;a href="https://github.com/kubernetes/git-sync"&gt;git-sync&lt;/a&gt; utility inside an &lt;code&gt;initContainer&lt;/code&gt; of my Kubernetes &lt;code&gt;Deployment&lt;/code&gt;, but that's just for the sake of laziness and doesn't relate to the current work.&lt;/p&gt; &lt;h3&gt;Making tools available&lt;/h3&gt; &lt;p&gt;The first real interesting part of the implementation is:&lt;/p&gt; &lt;pre&gt; ... volumes: - name: java csi: driver: toolprovider.csi.katalogos.dev volumeAttributes: image: quay.io/dfestal/csi-tool-openjdk11u-jdk_x64_linux_hotspot_11.0.9.1_1:latest - name: maven csi: driver: toolprovider.csi.katalogos.dev volumeAttributes: image: quay.io/dfestal/csi-tool-maven-3.6.3:latest ... &lt;/pre&gt; &lt;p&gt;This configuration uses the new CSI driver to expose my two &lt;a href="https://github.com/katalogos/csi-based-tool-provider/tree/master/examples/catalog"&gt;tooling images&lt;/a&gt; as CSI read-only volumes.&lt;/p&gt; &lt;h3&gt;Mounting the tools&lt;/h3&gt; &lt;p&gt;The following configuration makes Java and Maven installations available for the main pod container to mount them at the needed place:&lt;/p&gt; &lt;pre&gt; ... containers: - name: main ... env: ... - name: JAVA_HOME value: /usr/lib/jvm/jdk-11 - name: M2_HOME value: /opt/apache-maven-3.6.3 volumeMounts: - name: java mountPath: /usr/lib/jvm/jdk-11 - name: maven mountPath: /opt/apache-maven-3.6.3 ... &lt;/pre&gt; &lt;p&gt;Note that the pod container owns the final path where the Java and Maven installations will be mounted. So the pod container can also set the related environment variables to the right paths.&lt;/p&gt; &lt;h3&gt;Using the mounted tools&lt;/h3&gt; &lt;p&gt;Finally, the container that will build and run the application source code in development mode can be based on a bare operating system image, and has nothing more to do than call the &lt;a href="https://quarkus.io/guides/getting-started#running-the-application"&gt;recommended startup command&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; ... - name: main image: registry.access.redhat.com/ubi8/ubi args: - ./mvnw - compile - quarkus:dev - -Dquarkus.http.host=0.0.0.0 workingDir: /src/quarkus-quickstarts/getting-started ... &lt;/pre&gt; &lt;p&gt;The example will start on a &lt;a href="https://developers.redhat.com/products/rhel/ubi"&gt;Red Hat Universal Base Image&lt;/a&gt;. But the great thing is that you can make changes, such as switching to an Ubuntu image, and the server will start and run the same way without any other change. And if you want to switch to another version of Maven, just change the reference to the corresponding container image in the &lt;code&gt;maven&lt;/code&gt; CSI volume.&lt;/p&gt; &lt;p&gt;If you scale up this deployment to ten pods, the same underlying Java and Maven installations will be used. No files will be duplicated on the disk, and no additional containers will be created on the cluster node. Only additional bind mounts will be issued on the cluster node. And the space savings will be the same, however many workloads use the Java and Maven tooling images on this node.&lt;/p&gt; &lt;h3&gt;What about performance?&lt;/h3&gt; &lt;p&gt;In the very first implementation, the new &lt;code&gt;csi-based-tool-provider&lt;/code&gt; driver ran &lt;a href="https://github.com/containers/buildah/blob/master/docs/buildah-manifest.md"&gt;buildah manifest&lt;/a&gt; commands to store the various metadata related to mounted images, along with the associated containers and volumes, inside an &lt;a href="https://github.com/opencontainers/image-spec/blob/master/manifest.md#oci-image-manifest-specification"&gt;OCI manifest&lt;/a&gt;. Although this design was useful to get a POC working quickly, it required hard locks on the whole CSI mounting and unmounting process (&lt;code&gt;NodePublishVolume&lt;/code&gt; and &lt;code&gt;NodeUnpublishVolume&lt;/code&gt; CSI requests), in order to avoid concurrent modification of this global index and ensure consistency. Moreover, the &lt;code&gt;buildah&lt;/code&gt; container was initially created on the fly at mount time if necessary, and as soon as a given tool was not mounted by any pod container anymore, the corresponding &lt;code&gt;buildah&lt;/code&gt; container was removed by the CSI driver.&lt;/p&gt; &lt;p&gt;This design could lead to a mount delay of several seconds, especially when mounting an image for the first time. Instead of that design, the driver now uses an embeddable, high-performance, transactional key-value database called &lt;a href="https://github.com/dgraph-io/badger"&gt;BadgerDB&lt;/a&gt;. This choice allows much better performance and less contention caused by read-write locks. In addition, the list of container images exposed to the driver is now configured through a &lt;a href="https://kubernetes.io/docs/concepts/configuration/configmap/#mounted-configmaps-are-updated-automatically"&gt;mounted ConfigMap&lt;/a&gt;. Images, as well as their related &lt;code&gt;buildah&lt;/code&gt; containers, are managed, created, and cleaned up in background tasks. These two simple changes have reduced the average volume mount delay to some fractions of a second, as shown by the graph of the related &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; metric in Figure 1.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/lJzq7mN.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/lJzq7mN.png?itok=k7FMYerB" width="556" height="265" alt="Composable software catalogs on Kubernetes: Average volume mount delay for a tool is between 15 and 20 ms." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The average volume mount delay for updated containers. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Average volume mount delay for updated containers.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;On a local &lt;a href="https://minikube.sigs.k8s.io/docs/"&gt;Minikube&lt;/a&gt; installation, for a simple pod containing one mounted CSI volume with the JDK image mentioned earlier, and one very simple container (doing nothing more than listing the content of the mounted volume and then sleeping), the average delay required to mount the JDK inside the Pod fluctuated between 15 and 20 milliseconds. In comparison with the overall pod startup duration (between 1 and 3 seconds), this is pretty insignificant.&lt;/p&gt; &lt;h3&gt;Testing the example&lt;/h3&gt; &lt;p&gt;The related code is available in the &lt;a href="https://github.com/katalogos/csi-based-tool-provider"&gt;csi-based-tool-provider&lt;/a&gt; GitHub repository, including instructions on how to test it using pre-built container images.&lt;/p&gt; &lt;h2&gt;Additional use cases for composable software catalogs&lt;/h2&gt; &lt;p&gt;Beyond the example used in this article, we can foresee concrete use cases where such tool injection would be useful. First, it reduces the combinatorial-explosion effect of having to manage, in a single container image, the versioning and lifecycle of both the underlying system and all the various system-independent tools. So it could reduce the overall size of image layers stored on Kubernetes cluster nodes.&lt;/p&gt; &lt;h3&gt;Red Hat OpenShift Web Terminal&lt;/h3&gt; &lt;p&gt;The &lt;a href="https://www.openshift.com/blog/a-deeper-look-at-the-web-terminal-operator-1"&gt;Red Hat OpenShift Web Terminal&lt;/a&gt; is an example of a tool that could benefit from a software catalog. When opening a web terminal, the OpenShift console starts a pod with a container embedding all the typically required CLI tools. But if you need additional tools, you will have to replace this default container image with your own customized one, built by your own means. This build would not be necessary if we could provide all the CLI tools as volumes in a basic container. Composable software catalogs would also relieve the &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;continuous integration&lt;/a&gt; (CI) burden of having to rebuild the all-in-one container image each time one of the tools has to be updated. Going one step further, a catalog should allow using, in the web terminal, exactly the same version of the Kubernetes-related command-line tools (like &lt;code&gt;oc&lt;/code&gt; and &lt;code&gt;kubectl&lt;/code&gt;) as the version of the underlying OpenShift cluster.&lt;/p&gt; &lt;h3&gt;Tekton pipelines&lt;/h3&gt; &lt;p&gt;I also imagine how composable software catalogs could be used to inject off-the-shelf build tools into &lt;a href="https://github.com/tektoncd/pipeline/blob/master/docs/tasks.md#defining-steps"&gt;Tekton Task Steps&lt;/a&gt;. Here as well, there would be no more need to change and possibly rebuild Step container images each time you want to run your pipeline with different build tool variants or versions.&lt;/p&gt; &lt;h3&gt;Cloud IDEs&lt;/h3&gt; &lt;p&gt;Last but not least, composable software catalogs could benefit the various cloud-enabled IDEs, such as &lt;a href="https://www.eclipse.org/che/"&gt;Eclipse Che.&lt;/a&gt; The catalogs would make it really easy to:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Efficiently switch the Java or Maven installations in a workspace&lt;/li&gt; &lt;li&gt;Share these installations among the various containers&lt;/li&gt; &lt;li&gt;Have several versions at the same time&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Here as well, this new approach could greatly reduce the CI burden. We could stop building and maintaining a container image for each combination of underlying OS and tools. And composable software catalogs would finally unlock the combination of developer tools at runtime according to the developer's needs.&lt;/p&gt; &lt;h2&gt;What next?&lt;/h2&gt; &lt;p&gt;Although the proof of concept presented in this article is in an early alpha stage, we can already imagine some of the next steps to move it forward.&lt;/p&gt; &lt;h3&gt;Welcoming Katalogos&lt;/h3&gt; &lt;p&gt;A lot can be built on the foundation of the &lt;code&gt;csi-based-tool-provider&lt;/code&gt;. But as a first step, we should certainly set up a wider project dedicated to Kubernetes composable software catalogs. The CSI driver would be its first core component. So we've called this project Katalogos, from the ancient Greek word for a catalog: a register, especially one used for enrollment.&lt;/p&gt; &lt;h3&gt;Packaging the project as a complete solution&lt;/h3&gt; &lt;p&gt;Once the wider Katalogos project is bootstrapped, these next steps come to mind:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Add a Software Catalog Manager component to organize, pull, and manage images as software catalogs and make them available to the CSI driver on each cluster node.&lt;/li&gt; &lt;li&gt;Build an operator to install the CSI driver as well as configure the Software Catalog Manager.&lt;/li&gt; &lt;li&gt;Define a way to easily inject the required CSI volumes, as well as related environment variables, into pods according to annotations.&lt;/li&gt; &lt;li&gt;Provide related tooling and processes to easily build software catalogs that can feed the Software Catalog Manager.&lt;/li&gt; &lt;li&gt;Extend the mechanism to support the more complex case of software packages that are not inherently self-contained.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Getting feedback and building a community&lt;/h3&gt; &lt;p&gt;This article presented some ideas, with a minimal proof of concept, for a project that, I believe, could meet a real need in the current state of cloud-native development. The article is also a bid to get feedback, spark interest, and gather other use cases where the concept would fit. So, please comment, try the examples, open issues, fork the GitHub repository ... or simply star it.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/08/20/composable-software-catalogs-kubernetes-easier-way-update-containerized" title="Composable software catalogs on Kubernetes: An easier way to update containerized applications"&gt;Composable software catalogs on Kubernetes: An easier way to update containerized applications&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Qu9uHZyp9gE" height="1" width="1" alt=""/&gt;</summary><dc:creator>David Festal</dc:creator><dc:date>2021-08-20T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/08/20/composable-software-catalogs-kubernetes-easier-way-update-containerized</feedburner:origLink></entry><entry><title type="html">Season 3 and 60th Insights episode</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ansEqTkd-_k/" /><author><name>Max Rydahl Andersen</name></author><id>https://quarkus.io/blog/60th-quarkus-insights/</id><updated>2021-08-20T00:00:00Z</updated><content type="html">After a summer break and little bit of COVID-19 delay, we will finally have the 60th(!) Quarkus Insights episode on Monday the 23rd August. For those who don’t know, Quarkus Insights is a (almost) weekly video/audio podcast where we host people from all parts of the Quarkiverse to sit down...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ansEqTkd-_k" height="1" width="1" alt=""/&gt;</content><dc:creator>Max Rydahl Andersen</dc:creator><feedburner:origLink>https://quarkus.io/blog/60th-quarkus-insights/</feedburner:origLink></entry><entry><title>Cluster tooling updates and more in Red Hat OpenShift's Web Terminal Operator 1.3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/J3giX7F6Bw4/cluster-tooling-updates-and-more-red-hat-openshifts-web-terminal-operator-13" /><author><name>Josh Pinkney, Angel Misevski</name></author><id>fb68ba28-3337-4201-86cb-5d45789412d4</id><updated>2021-08-19T07:00:00Z</updated><published>2021-08-19T07:00:00Z</published><summary type="html">&lt;p&gt;The Web Terminal Operator in &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; provides a web terminal with common cluster tooling pre-installed. The operator gives you the power and flexibility to work with your product directly through the OpenShift web console, eliminating the need to have all your tooling installed locally.&lt;/p&gt; &lt;p&gt;This article is an overview of the new features introduced in Web Terminal Operator 1.3. These improvements include depending on the newly released DevWorkspace Operator, adding support for saving your home directory, and updating our tooling to be compatible with OpenShift 4.8.&lt;/p&gt; &lt;h2&gt;DevWorkspace Operator dependency&lt;/h2&gt; &lt;p&gt;Previously, the Web Terminal Operator relied on an embedded version of the &lt;a href="https://github.com/devfile/devworkspace-operator/"&gt;DevWorkspace controller&lt;/a&gt; to provide support for web terminals. That meant that in order to get the latest and greatest changes for the DevWorkspace controller, you had to wait three months for a new Web Terminal Operator release. As of Web Terminal 1.3, we have extracted that dependency, released the DevWorkspace Operator as its own separate operator, and now depend on that for providing support for web terminals. What this means for you is that the engine “under the hood” (the DevWorkspace Operator) will be updated every six weeks, instead of the standard three-month schedule for the Web Terminal Operator.&lt;/p&gt; &lt;h2&gt;Saving your home directory&lt;/h2&gt; &lt;p&gt;With Web Terminal 1.3, you will be able to mount your home directory and persist changes to your web terminal over multiple restarts. This feature isn’t enabled by default and it requires some additional configuration. This additional configuration depends on whether or not you already have a web terminal.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Only a web terminal that has a volume and volume mount for &lt;code&gt;/home/user&lt;/code&gt; will persist the home directory. Details follow.&lt;/p&gt; &lt;h3&gt;If you already have a web terminal&lt;/h3&gt; &lt;p&gt;In order to persist the home directory over multiple restarts, you will need to update the custom resource to mount a volume into the web terminal tooling container:&lt;/p&gt; &lt;p&gt;First, get your web terminal custom resource in your namespace and open it up for editing:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;oc get dw -n ${your_namespace} oc edit dw ${your web terminal name} -n ${your_namespace}&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that you have your custom resource open for editing, modify the DevWorkspace custom resource components section to add a mount for the storage. This can be done by first defining a volume in &lt;code&gt;spec.template.components&lt;/code&gt; and then mounting that volume in the web terminal tooling container. The highlighted portion of the YAML file in Figure 1 shows what you need to add in order to get the mount.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/terminal_mount.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/terminal_mount.png?itok=n82YvfnY" width="580" height="612" alt="The configuration of your DevWorkspace must have a section mounting the /home/user directory" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Configuration file with a section mounting the /home/user directory. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Once your custom resource has been edited and saved, you can start a new web terminal and create changes under &lt;code&gt;/home/user&lt;/code&gt;. Your changes will persist over multiple restarts.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are editing the custom resource inside a web terminal, the web terminal will automatically apply the changes and then close the active web terminal. To reopen the web terminal with the changes applied, click the &lt;strong&gt;Restart Terminal&lt;/strong&gt; button.&lt;/p&gt; &lt;h3&gt;If you don’t already have a web terminal&lt;/h3&gt; &lt;p&gt;In order to persist the home directory if you don’t already have a web terminal, you can edit your configuration file and add the following fields. In the YAML shown, replace &lt;code&gt;${your namespace}&lt;/code&gt; with the namespace where you want to create the web terminal.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you are an admin, you must create your web terminal in &lt;code&gt;openshift-terminal&lt;/code&gt;, otherwise you will not be able to connect to the web terminal through the OpenShift web console. If the &lt;code&gt;openshift-terminal&lt;/code&gt; namespace does not currently exist, you must start your first web terminal through the UI so that the namespace is provisioned.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;kind: DevWorkspace apiVersion: workspace.devfile.io/v1alpha2 metadata: name: web-terminal namespace: ${your namespace} annotations: controller.devfile.io/restricted-access: "true" labels: console.openshift.io/terminal: "true" spec: started: true routingClass: 'web-terminal' template: components: - name: web-terminal-exec plugin: kubernetes: name: web-terminal-exec namespace: openshift-operators - name: web-terminal-tooling plugin: kubernetes: name: web-terminal-tooling namespace: openshift-operators components: - name: web-terminal-tooling container: volumeMounts: - name: home-storage path: "/home/user" - name: home-storage volume: {}&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once your web terminal custom resource has been created, you can start a web terminal and all your changes under &lt;code&gt;/home/user&lt;/code&gt; will be persisted by default.&lt;/p&gt; &lt;h2&gt;Tooling update&lt;/h2&gt; &lt;p&gt;We have updated the default binaries in Web Terminal Operator 1.3 to include the latest versions of the built-in command-line tools, as shown in Table 1.&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="388"&gt;&lt;caption&gt;Table 1: Command-line tools in Web Terminal Operator 1.3.&lt;/caption&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Binary&lt;/strong&gt;&lt;/th&gt; &lt;th&gt;&lt;strong&gt;Old version&lt;/strong&gt;&lt;/th&gt; &lt;th&gt;&lt;strong&gt;New version&lt;/strong&gt;&lt;/th&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;oc&lt;/code&gt;&lt;/td&gt; &lt;td&gt;4.7.0&lt;/td&gt; &lt;td&gt;4.8.2&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubectl&lt;/code&gt;&lt;/td&gt; &lt;td&gt;v1.20.1&lt;/td&gt; &lt;td&gt;v0.21.0-beta.1&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;odo&lt;/code&gt;&lt;/td&gt; &lt;td&gt;2.0.4&lt;/td&gt; &lt;td&gt;2.2.3&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;knative&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.19.1&lt;/td&gt; &lt;td&gt;0.21.0&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;tekton&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.15.0&lt;/td&gt; &lt;td&gt;0.17.2&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubectx&lt;/code&gt;&lt;/td&gt; &lt;td&gt;v0.9.3&lt;/td&gt; &lt;td&gt;v0.9.4&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubens&lt;/code&gt;&lt;/td&gt; &lt;td&gt;v0.9.3&lt;/td&gt; &lt;td&gt;v0.9.4&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;rhoas&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.24.1&lt;/td&gt; &lt;td&gt;0.25.0&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;submariner&lt;/code&gt;&lt;/td&gt; &lt;td&gt; &lt;/td&gt; &lt;td&gt;0.9.1 (First release)&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;h2&gt;Try out these features&lt;/h2&gt; &lt;p&gt;In Web Terminal 1.3 we have changed the default channel from alpha to fast. This means that you’ll have to go through some extra steps to try out these new features:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;If your cluster already has the Web Terminal Operator installed, uninstall it by following the &lt;a href="https://docs.openshift.com/container-platform/4.7/web_console/odc-about-web-terminal.html#deleting-the-web-terminal-components-and-custom-resources"&gt;uninstall instructions&lt;/a&gt; and re-install the Web Terminal Operator using the fast channel.&lt;/li&gt; &lt;li&gt;If your cluster does not have the Web Terminal Operator installed, install it using the fast channel.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;For a peek into how the Web Terminal Operator works under the hood, please see &lt;a href="https://www.openshift.com/blog/a-deeper-look-at-the-web-terminal-operator-1"&gt;A deeper look at the Web Terminal Operator&lt;/a&gt; by Angel Misevski. You can also check out the initial release article by Joshua Wood: &lt;a href="https://developers.redhat.com/blog/2020/10/01/command-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview/"&gt;Command-line cluster management with Red Hat OpenShift’s new web terminal&lt;/a&gt;. For a look at our previous release blog, read &lt;a href="https://developers.redhat.com/blog/2021/03/08/whats-new-in-red-hat-openshifts-web-terminal-operator-1-2"&gt;What’s new in Red Hat OpenShift's Web Terminal Operator 1.2&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/08/19/cluster-tooling-updates-and-more-red-hat-openshifts-web-terminal-operator-13" title="Cluster tooling updates and more in Red Hat OpenShift's Web Terminal Operator 1.3"&gt;Cluster tooling updates and more in Red Hat OpenShift's Web Terminal Operator 1.3&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/J3giX7F6Bw4" height="1" width="1" alt=""/&gt;</summary><dc:creator>Josh Pinkney, Angel Misevski</dc:creator><dc:date>2021-08-19T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/08/19/cluster-tooling-updates-and-more-red-hat-openshifts-web-terminal-operator-13</feedburner:origLink></entry></feed>
